Train_Data_2 = TraVal_Data_2[Train_Index_2,]
Validation_Data_2 = TraVal_Data_2[-Train_Index_2,] # rest as validation
#normalize
train.norm.df_2 <- Train_Data_2
valid.norm.df_2 <- Validation_Data_2
traval.norm.df_2 <- TraVal_Data_2
test.norm.df_2 <- Test_Data_2
norm.values_2 <- preProcess(Train_Data_2[, 0:5], method=c("center", "scale"))
train.norm.df_2[, 1:6] <- predict(norm.values_2, Train_Data_2[, 0:5]) # Replace first two columns with normalized values
valid.norm.df_2[, 1:6] <- predict(norm.values_2, Validation_Data_2[, 0:5])
traval.norm.df_2[, 1:6] <- predict(norm.values_2, traval.norm.df_2[, 0:5])
test.norm.df_2[, 1:6] <- predict(norm.values_2, Test_Data_2[, 0:5])
predicted_test_labels_2 <- knn(train = train.norm.df_2[,-7], test = test.norm.df_2[,-7], cl = train.norm.df_2$Personal.Loan, k = 7)
#Train confusion matrix
CrossTable(x=train.norm.df_2$Personal.Loan,y=predicted_test_labels_2, prop.chisq = FALSE)
#Test confusion matrix
CrossTable(x=test.norm.df_2$Personal.Loan,y=predicted_train_labels_2, prop.chisq = FALSE)
#Read data
DF=read.csv("./UniversalBank.csv") # Read the Online Retail csv file
#Load libraries
library(dplyr)
library(caret)
library(ISLR)
library(FNN)
library(gmodels)
set.seed(15)
#Select variables in need
DF <- select(DF, Age, Experience, Income, Family, CCAvg, Education, Mortgage, Personal.Loan, Securities.Account, CD.Account, Online, CreditCard) # Select a subset of variables
#Create dummy variables for Education (categorical variable with 2+ levels)
DF$Education_1 <- as.integer(DF$Education == 1)
DF$Education_2 <- as.integer(DF$Education == 2)
DF$Education_3 <- as.integer(DF$Education == 3)
#Drop no longer needed Education field
DF<-DF[,-6]
#Partition Data into 60% Train, 40% val
Train_Index=createDataPartition(DF$Age,p=0.60, list=FALSE)
Train_Data = DF[Train_Index,] # create the training data; we include all columns; note the index is row, column
Val_Data = DF[-Train_Index,] # create the val set
#Create copy of data for normalization
train.norm.df <- Train_Data
val.norm.df <- Val_Data
# use preProcess() from the caret package to normalize data
norm.values <- preProcess(Train_Data[,0:5], method=c("center", "scale"))
#Replace first 6 columns with normalized values
train.norm.df[,1:6] <- predict(norm.values, Train_Data[,0:5])
val.norm.df[,1:6] <- predict(norm.values, Val_Data[,0:5])
#Train knn model on all variables except personal loan status since that's our target variable
#nn<-knn(train = train.norm.df[,-7], val = val.norm.df[,-7], cl=train.norm.df$Personal.Loan,k=1)
#Load a custom customer
custom_customer_data <- data.frame(
Age = c(40),
Experience = c(10),
Income = c(84),
Family = c(2),
CCAvg = c(2),
Mortgage = c(0),
Personal.Loan = c(0),
Securities.Account = c(0),
CD.Account = c(0),
Online = c(1),
Credit.Card = c(1),
Education_1 = c(0),
Education_2 = c(1),
Education_3 = c(0)
)
#Normalize customer data
customer.norm.df <- custom_customer_data
customer.norm.df[,1:6] <- predict(norm.values, custom_customer_data[,0:5])
#Question 1)
# This customer would be classified as not accepting the loan.
classification <- knn(train = train.norm.df[,-7], test = customer.norm.df[,-7], cl = train.norm.df$Personal.Loan, k = 1)
# Add the predictions to the new data
new_customer_data <- customer.norm.df
new_customer_data$LoanAcceptance <- classification
# Print the new data with predicted classification
print(new_customer_data)
#End question 1
#Question 2)
#Training the model, RMSE was used to select the optimal model using the smallest value. The final value used for the model was k = 7.
#train model for k
set.seed(123)
model<-train(Personal.Loan~Age+Experience+Income+Family+CCAvg+Mortgage+Securities.Account+CD.Account+Online+CreditCard+Education_1+Education_2+Education_3, data=train.norm.df, method="knn")
model
#End question 2
#Question 3) Show confusion matrix
predicted_test_labels <- knn(train = train.norm.df[,-7], test = val.norm.df[,-7], cl = train.norm.df$Personal.Loan, k = 7)
CrossTable(x=val.norm.df$Personal.Loan,y=predicted_test_labels, prop.chisq = FALSE)
# End question 3
#Question 4) try again with optimal k
# The customer would still not be classified as accepting the loan
classification <- knn(train = train.norm.df[,-7], test = customer.norm.df[,-7], cl = train.norm.df$Personal.Loan, k = 7)
new_customer_data_k7 <- customer.norm.df
new_customer_data_k7$LoanAcceptance <- classification
# Print the new data with predicted classification
print(new_customer_data_k7)
#Question 5)
#Re-partition Data into 50% Train, 30% validation 20% test
Test_Index_2 = createDataPartition(DF$Age,p=0.2, list=FALSE) # 20% reserved for Test
Test_Data_2 = DF[Test_Index_2,]
TraVal_Data_2 = DF[-Test_Index_2,] # Validation and Training data is rest
Train_Index_2 = createDataPartition(TraVal_Data_2$Age,p=0.75, list=FALSE) # 75% of remaining data as training
Train_Data_2 = TraVal_Data_2[Train_Index_2,]
Validation_Data_2 = TraVal_Data_2[-Train_Index_2,] # rest as validation
#normalize
train.norm.df_2 <- Train_Data_2
valid.norm.df_2 <- Validation_Data_2
traval.norm.df_2 <- TraVal_Data_2
test.norm.df_2 <- Test_Data_2
norm.values_2 <- preProcess(Train_Data_2[, 0:5], method=c("center", "scale"))
train.norm.df_2[, 1:6] <- predict(norm.values_2, Train_Data_2[, 0:5]) # Replace first two columns with normalized values
valid.norm.df_2[, 1:6] <- predict(norm.values_2, Validation_Data_2[, 0:5])
traval.norm.df_2[, 1:6] <- predict(norm.values_2, traval.norm.df_2[, 0:5])
test.norm.df_2[, 1:6] <- predict(norm.values_2, Test_Data_2[, 0:5])
predicted_test_labels_2 <- knn(train = train.norm.df_2[,-7], test = test.norm.df_2[,-7], cl = train.norm.df_2$Personal.Loan, k = 7)
#Train confusion matrix
#CrossTable(x=train.norm.df_2$Personal.Loan,y=predicted_test_labels_2, prop.chisq = FALSE)
#Val confusion Matrix
#CrossTable(x=val.norm.df_2$Personal.Loan,y=predicted_train_labels_2, prop.chisq = FALSE)
#Test confusion matrix
CrossTable(x=test.norm.df_2$Personal.Loan,y=predicted_train_labels_2, prop.chisq = FALSE)
#Read data
DF=read.csv("./UniversalBank.csv") # Read the Online Retail csv file
#Load libraries
library(dplyr)
library(caret)
library(ISLR)
library(FNN)
library(gmodels)
set.seed(15)
#Select variables in need
DF <- select(DF, Age, Experience, Income, Family, CCAvg, Education, Mortgage, Personal.Loan, Securities.Account, CD.Account, Online, CreditCard) # Select a subset of variables
#Create dummy variables for Education (categorical variable with 2+ levels)
DF$Education_1 <- as.integer(DF$Education == 1)
DF$Education_2 <- as.integer(DF$Education == 2)
DF$Education_3 <- as.integer(DF$Education == 3)
#Drop no longer needed Education field
DF<-DF[,-6]
#Partition Data into 60% Train, 40% val
Train_Index=createDataPartition(DF$Age,p=0.60, list=FALSE)
Train_Data = DF[Train_Index,] # create the training data; we include all columns; note the index is row, column
Val_Data = DF[-Train_Index,] # create the val set
#Create copy of data for normalization
train.norm.df <- Train_Data
val.norm.df <- Val_Data
# use preProcess() from the caret package to normalize data
norm.values <- preProcess(Train_Data[,0:5], method=c("center", "scale"))
#Replace first 6 columns with normalized values
train.norm.df[,1:6] <- predict(norm.values, Train_Data[,0:5])
val.norm.df[,1:6] <- predict(norm.values, Val_Data[,0:5])
#Train knn model on all variables except personal loan status since that's our target variable
#nn<-knn(train = train.norm.df[,-7], val = val.norm.df[,-7], cl=train.norm.df$Personal.Loan,k=1)
#Load a custom customer
custom_customer_data <- data.frame(
Age = c(40),
Experience = c(10),
Income = c(84),
Family = c(2),
CCAvg = c(2),
Mortgage = c(0),
Personal.Loan = c(0),
Securities.Account = c(0),
CD.Account = c(0),
Online = c(1),
Credit.Card = c(1),
Education_1 = c(0),
Education_2 = c(1),
Education_3 = c(0)
)
#Normalize customer data
customer.norm.df <- custom_customer_data
customer.norm.df[,1:6] <- predict(norm.values, custom_customer_data[,0:5])
#Question 1)
# This customer would be classified as not accepting the loan.
classification <- knn(train = train.norm.df[,-7], test = customer.norm.df[,-7], cl = train.norm.df$Personal.Loan, k = 1)
# Add the predictions to the new data
new_customer_data <- customer.norm.df
new_customer_data$LoanAcceptance <- classification
# Print the new data with predicted classification
print(new_customer_data)
#End question 1
#Question 2)
#Training the model, RMSE was used to select the optimal model using the smallest value. The final value used for the model was k = 7.
#train model for k
set.seed(123)
model<-train(Personal.Loan~Age+Experience+Income+Family+CCAvg+Mortgage+Securities.Account+CD.Account+Online+CreditCard+Education_1+Education_2+Education_3, data=train.norm.df, method="knn")
model
#End question 2
#Question 3) Show confusion matrix
predicted_test_labels <- knn(train = train.norm.df[,-7], test = val.norm.df[,-7], cl = train.norm.df$Personal.Loan, k = 7)
CrossTable(x=val.norm.df$Personal.Loan,y=predicted_test_labels, prop.chisq = FALSE)
# End question 3
#Question 4) try again with optimal k
# The customer would still not be classified as accepting the loan
classification <- knn(train = train.norm.df[,-7], test = customer.norm.df[,-7], cl = train.norm.df$Personal.Loan, k = 7)
new_customer_data_k7 <- customer.norm.df
new_customer_data_k7$LoanAcceptance <- classification
# Print the new data with predicted classification
print(new_customer_data_k7)
#Question 5)
#Re-partition Data into 50% Train, 30% validation 20% test
Test_Index_2 = createDataPartition(DF$Age,p=0.2, list=FALSE) # 20% reserved for Test
Test_Data_2 = DF[Test_Index_2,]
TraVal_Data_2 = DF[-Test_Index_2,] # Validation and Training data is rest
Train_Index_2 = createDataPartition(TraVal_Data_2$Age,p=0.75, list=FALSE) # 75% of remaining data as training
Train_Data_2 = TraVal_Data_2[Train_Index_2,]
Validation_Data_2 = TraVal_Data_2[-Train_Index_2,] # rest as validation
#normalize
train.norm.df_2 <- Train_Data_2
valid.norm.df_2 <- Validation_Data_2
traval.norm.df_2 <- TraVal_Data_2
test.norm.df_2 <- Test_Data_2
norm.values_2 <- preProcess(Train_Data_2[, 0:5], method=c("center", "scale"))
train.norm.df_2[, 1:6] <- predict(norm.values_2, Train_Data_2[, 0:5]) # Replace first two columns with normalized values
valid.norm.df_2[, 1:6] <- predict(norm.values_2, Validation_Data_2[, 0:5])
traval.norm.df_2[, 1:6] <- predict(norm.values_2, traval.norm.df_2[, 0:5])
test.norm.df_2[, 1:6] <- predict(norm.values_2, Test_Data_2[, 0:5])
predicted_test_labels_2 <- knn(train = train.norm.df_2[,-7], test = test.norm.df_2[,-7], cl = train.norm.df_2$Personal.Loan, k = 7)
#Train confusion matrix
#CrossTable(x=train.norm.df_2$Personal.Loan,y=predicted_test_labels_2, prop.chisq = FALSE)
#Val confusion Matrix
#CrossTable(x=val.norm.df_2$Personal.Loan,y=predicted_test_labels_2, prop.chisq = FALSE)
#Test confusion matrix
CrossTable(x=test.norm.df_2$Personal.Loan,y=predicted_test_labels_2, prop.chisq = FALSE)
#Read data
DF=read.csv("./UniversalBank.csv") # Read the Online Retail csv file
#Load libraries
library(dplyr)
library(caret)
library(ISLR)
library(FNN)
library(gmodels)
set.seed(15)
#Select variables in need
DF <- select(DF, Age, Experience, Income, Family, CCAvg, Education, Mortgage, Personal.Loan, Securities.Account, CD.Account, Online, CreditCard) # Select a subset of variables
#Create dummy variables for Education (categorical variable with 2+ levels)
DF$Education_1 <- as.integer(DF$Education == 1)
DF$Education_2 <- as.integer(DF$Education == 2)
DF$Education_3 <- as.integer(DF$Education == 3)
#Drop no longer needed Education field
DF<-DF[,-6]
#Partition Data into 60% Train, 40% val
Train_Index=createDataPartition(DF$Age,p=0.60, list=FALSE)
Train_Data = DF[Train_Index,] # create the training data; we include all columns; note the index is row, column
Val_Data = DF[-Train_Index,] # create the val set
#Create copy of data for normalization
train.norm.df <- Train_Data
val.norm.df <- Val_Data
# use preProcess() from the caret package to normalize data
norm.values <- preProcess(Train_Data[,0:5], method=c("center", "scale"))
#Replace first 6 columns with normalized values
train.norm.df[,1:6] <- predict(norm.values, Train_Data[,0:5])
val.norm.df[,1:6] <- predict(norm.values, Val_Data[,0:5])
#Train knn model on all variables except personal loan status since that's our target variable
#nn<-knn(train = train.norm.df[,-7], val = val.norm.df[,-7], cl=train.norm.df$Personal.Loan,k=1)
#Load a custom customer
custom_customer_data <- data.frame(
Age = c(40),
Experience = c(10),
Income = c(84),
Family = c(2),
CCAvg = c(2),
Mortgage = c(0),
Personal.Loan = c(0),
Securities.Account = c(0),
CD.Account = c(0),
Online = c(1),
Credit.Card = c(1),
Education_1 = c(0),
Education_2 = c(1),
Education_3 = c(0)
)
#Normalize customer data
customer.norm.df <- custom_customer_data
customer.norm.df[,1:6] <- predict(norm.values, custom_customer_data[,0:5])
#Question 1)
# This customer would be classified as not accepting the loan.
classification <- knn(train = train.norm.df[,-7], test = customer.norm.df[,-7], cl = train.norm.df$Personal.Loan, k = 1)
# Add the predictions to the new data
new_customer_data <- customer.norm.df
new_customer_data$LoanAcceptance <- classification
# Print the new data with predicted classification
print(new_customer_data)
#End question 1
#Question 2)
#Training the model, RMSE was used to select the optimal model using the smallest value. The final value used for the model was k = 7.
#train model for k
set.seed(123)
model<-train(Personal.Loan~Age+Experience+Income+Family+CCAvg+Mortgage+Securities.Account+CD.Account+Online+CreditCard+Education_1+Education_2+Education_3, data=train.norm.df, method="knn")
model
#End question 2
#Question 3) Show confusion matrix
predicted_test_labels <- knn(train = train.norm.df[,-7], test = val.norm.df[,-7], cl = train.norm.df$Personal.Loan, k = 7)
CrossTable(x=val.norm.df$Personal.Loan,y=predicted_test_labels, prop.chisq = FALSE)
# End question 3
#Question 4) try again with optimal k
# The customer would still not be classified as accepting the loan
classification <- knn(train = train.norm.df[,-7], test = customer.norm.df[,-7], cl = train.norm.df$Personal.Loan, k = 7)
new_customer_data_k7 <- customer.norm.df
new_customer_data_k7$LoanAcceptance <- classification
# Print the new data with predicted classification
print(new_customer_data_k7)
#Question 5)
#Re-partition Data into 50% Train, 30% validation 20% test
Test_Index_2 = createDataPartition(DF$Age,p=0.2, list=FALSE) # 20% reserved for Test
Test_Data_2 = DF[Test_Index_2,]
TraVal_Data_2 = DF[-Test_Index_2,] # Validation and Training data is rest
Train_Index_2 = createDataPartition(TraVal_Data_2$Age,p=0.75, list=FALSE) # 75% of remaining data as training
Train_Data_2 = TraVal_Data_2[Train_Index_2,]
Validation_Data_2 = TraVal_Data_2[-Train_Index_2,] # rest as validation
#normalize
train.norm.df_2 <- Train_Data_2
valid.norm.df_2 <- Validation_Data_2
traval.norm.df_2 <- TraVal_Data_2
test.norm.df_2 <- Test_Data_2
norm.values_2 <- preProcess(Train_Data_2[, 0:5], method=c("center", "scale"))
train.norm.df_2[, 1:6] <- predict(norm.values_2, Train_Data_2[, 0:5]) # Replace first two columns with normalized values
valid.norm.df_2[, 1:6] <- predict(norm.values_2, Validation_Data_2[, 0:5])
traval.norm.df_2[, 1:6] <- predict(norm.values_2, traval.norm.df_2[, 0:5])
test.norm.df_2[, 1:6] <- predict(norm.values_2, Test_Data_2[, 0:5])
predicted_train_labels_2 <- knn(train = train.norm.df_2[,-7], test = train.norm.df_2[,-7], cl = train.norm.df_2$Personal.Loan, k = 7)
predicted_val_labels_2 <- knn(train = train.norm.df_2[,-7], test = val.norm.df_2[,-7], cl = train.norm.df_2$Personal.Loan, k = 7)
#Read data
DF=read.csv("./UniversalBank.csv") # Read the Online Retail csv file
#Load libraries
library(dplyr)
library(caret)
library(ISLR)
library(FNN)
library(gmodels)
set.seed(15)
#Select variables in need
DF <- select(DF, Age, Experience, Income, Family, CCAvg, Education, Mortgage, Personal.Loan, Securities.Account, CD.Account, Online, CreditCard) # Select a subset of variables
#Create dummy variables for Education (categorical variable with 2+ levels)
DF$Education_1 <- as.integer(DF$Education == 1)
DF$Education_2 <- as.integer(DF$Education == 2)
DF$Education_3 <- as.integer(DF$Education == 3)
#Drop no longer needed Education field
DF<-DF[,-6]
#Partition Data into 60% Train, 40% val
Train_Index=createDataPartition(DF$Age,p=0.60, list=FALSE)
Train_Data = DF[Train_Index,] # create the training data; we include all columns; note the index is row, column
Val_Data = DF[-Train_Index,] # create the val set
#Create copy of data for normalization
train.norm.df <- Train_Data
val.norm.df <- Val_Data
# use preProcess() from the caret package to normalize data
norm.values <- preProcess(Train_Data[,0:5], method=c("center", "scale"))
#Replace first 6 columns with normalized values
train.norm.df[,1:6] <- predict(norm.values, Train_Data[,0:5])
val.norm.df[,1:6] <- predict(norm.values, Val_Data[,0:5])
#Train knn model on all variables except personal loan status since that's our target variable
#nn<-knn(train = train.norm.df[,-7], val = val.norm.df[,-7], cl=train.norm.df$Personal.Loan,k=1)
#Load a custom customer
custom_customer_data <- data.frame(
Age = c(40),
Experience = c(10),
Income = c(84),
Family = c(2),
CCAvg = c(2),
Mortgage = c(0),
Personal.Loan = c(0),
Securities.Account = c(0),
CD.Account = c(0),
Online = c(1),
Credit.Card = c(1),
Education_1 = c(0),
Education_2 = c(1),
Education_3 = c(0)
)
#Normalize customer data
customer.norm.df <- custom_customer_data
customer.norm.df[,1:6] <- predict(norm.values, custom_customer_data[,0:5])
#Question 1)
# This customer would be classified as not accepting the loan.
classification <- knn(train = train.norm.df[,-7], test = customer.norm.df[,-7], cl = train.norm.df$Personal.Loan, k = 1)
# Add the predictions to the new data
new_customer_data <- customer.norm.df
new_customer_data$LoanAcceptance <- classification
# Print the new data with predicted classification
print(new_customer_data)
#End question 1
#Question 2)
#Training the model, RMSE was used to select the optimal model using the smallest value. The final value used for the model was k = 7.
#train model for k
set.seed(123)
model<-train(Personal.Loan~Age+Experience+Income+Family+CCAvg+Mortgage+Securities.Account+CD.Account+Online+CreditCard+Education_1+Education_2+Education_3, data=train.norm.df, method="knn")
model
#End question 2
#Question 3) Show confusion matrix
predicted_test_labels <- knn(train = train.norm.df[,-7], test = val.norm.df[,-7], cl = train.norm.df$Personal.Loan, k = 7)
CrossTable(x=val.norm.df$Personal.Loan,y=predicted_test_labels, prop.chisq = FALSE)
# End question 3
#Question 4) try again with optimal k
# The customer would still not be classified as accepting the loan
classification <- knn(train = train.norm.df[,-7], test = customer.norm.df[,-7], cl = train.norm.df$Personal.Loan, k = 7)
new_customer_data_k7 <- customer.norm.df
new_customer_data_k7$LoanAcceptance <- classification
# Print the new data with predicted classification
print(new_customer_data_k7)
#Question 5)
#Re-partition Data into 50% Train, 30% validation 20% test
Test_Index_2 = createDataPartition(DF$Age,p=0.2, list=FALSE) # 20% reserved for Test
Test_Data_2 = DF[Test_Index_2,]
TraVal_Data_2 = DF[-Test_Index_2,] # Validation and Training data is rest
Train_Index_2 = createDataPartition(TraVal_Data_2$Age,p=0.75, list=FALSE) # 75% of remaining data as training
Train_Data_2 = TraVal_Data_2[Train_Index_2,]
Validation_Data_2 = TraVal_Data_2[-Train_Index_2,] # rest as validation
#normalize
train.norm.df_2 <- Train_Data_2
val.norm.df_2 <- Validation_Data_2
traval.norm.df_2 <- TraVal_Data_2
test.norm.df_2 <- Test_Data_2
norm.values_2 <- preProcess(Train_Data_2[, 0:5], method=c("center", "scale"))
train.norm.df_2[, 1:6] <- predict(norm.values_2, Train_Data_2[, 0:5]) # Replace first two columns with normalized values
val.norm.df_2[, 1:6] <- predict(norm.values_2, Validation_Data_2[, 0:5])
traval.norm.df_2[, 1:6] <- predict(norm.values_2, traval.norm.df_2[, 0:5])
test.norm.df_2[, 1:6] <- predict(norm.values_2, Test_Data_2[, 0:5])
predicted_train_labels_2 <- knn(train = train.norm.df_2[,-7], test = train.norm.df_2[,-7], cl = train.norm.df_2$Personal.Loan, k = 7)
predicted_val_labels_2 <- knn(train = train.norm.df_2[,-7], test = val.norm.df_2[,-7], cl = train.norm.df_2$Personal.Loan, k = 7)
predicted_test_labels_2 <- knn(train = train.norm.df_2[,-7], test = test.norm.df_2[,-7], cl = train.norm.df_2$Personal.Loan, k = 7)
#Train confusion matrix
CrossTable(x=train.norm.df_2$Personal.Loan,y=predicted_train_labels_2, prop.chisq = FALSE)
#Val confusion Matrix
CrossTable(x=val.norm.df_2$Personal.Loan,y=predicted_val_labels_2, prop.chisq = FALSE)
#Test confusion matrix
CrossTable(x=test.norm.df_2$Personal.Loan,y=predicted_test_labels_2, prop.chisq = FALSE)
---
title: "Assignment 2"
---
title: "Assignment 2"
#Read data
DF=read.csv("./UniversalBank.csv") # Read the Online Retail csv file
#Load libraries
library(dplyr)
library(caret)
library(ISLR)
library(FNN)
library(gmodels)
set.seed(15)
#Select variables in need
DF <- select(DF, Age, Experience, Income, Family, CCAvg, Education, Mortgage, Personal.Loan, Securities.Account, CD.Account, Online, CreditCard) # Select a subset of variables
#Create dummy variables for Education (categorical variable with 2+ levels)
DF$Education_1 <- as.integer(DF$Education == 1)
DF$Education_2 <- as.integer(DF$Education == 2)
DF$Education_3 <- as.integer(DF$Education == 3)
#Drop no longer needed Education field
DF<-DF[,-6]
#Partition Data into 60% Train, 40% val
Train_Index=createDataPartition(DF$Age,p=0.60, list=FALSE)
Train_Data = DF[Train_Index,] # create the training data; we include all columns; note the index is row, column
Val_Data = DF[-Train_Index,] # create the val set
#Create copy of data for normalization
train.norm.df <- Train_Data
val.norm.df <- Val_Data
# use preProcess() from the caret package to normalize data
norm.values <- preProcess(Train_Data[,0:5], method=c("center", "scale"))
#Replace first 6 columns with normalized values
train.norm.df[,1:6] <- predict(norm.values, Train_Data[,0:5])
val.norm.df[,1:6] <- predict(norm.values, Val_Data[,0:5])
#Train knn model on all variables except personal loan status since that's our target variable
#nn<-knn(train = train.norm.df[,-7], val = val.norm.df[,-7], cl=train.norm.df$Personal.Loan,k=1)
#Load a custom customer
custom_customer_data <- data.frame(
Age = c(40),
Experience = c(10),
Income = c(84),
Family = c(2),
CCAvg = c(2),
Mortgage = c(0),
Personal.Loan = c(0),
Securities.Account = c(0),
CD.Account = c(0),
Online = c(1),
Credit.Card = c(1),
Education_1 = c(0),
Education_2 = c(1),
Education_3 = c(0)
)
#Normalize customer data
customer.norm.df <- custom_customer_data
customer.norm.df[,1:6] <- predict(norm.values, custom_customer_data[,0:5])
#Question 1)
classification <- knn(train = train.norm.df, test = customer.norm.df, cl = train.norm.df$Personal.Loan, k = 1)
# Add the predictions to the new data
new_customer_data <- customer.norm.df
new_customer_data$LoanAcceptance <- classification
# Print the new data with predicted classification
print(new_customer_data)
View(customer.norm.df)
View(customer.norm.df)
View(new_customer_data)
View(new_customer_data)
DFtest <-DF
DFtest <-dummyVars(~Education,data=DF)
View(DFtest)
View(DFtest)
#Read data
DF=read.csv("./UniversalBank.csv") # Read the Online Retail csv file
#Load libraries
library(dplyr)
library(caret)
library(ISLR)
library(FNN)
library(gmodels)
set.seed(15)
#Select variables in need
DF <- select(DF, Age, Experience, Income, Family, CCAvg, Education, Mortgage, Personal.Loan, Securities.Account, CD.Account, Online, CreditCard) # Select a subset of variables
#Create dummy variables for Education (categorical variable with 2+ levels)
DFtest <-DF
DFtest <-dummyVars(~Education,data=DF)
View(DFtest)
View(DFtest)
